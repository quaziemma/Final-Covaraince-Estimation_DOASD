# -*- coding: utf-8 -*-
"""DOASD_Estimation(2)_(2)(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/quaziemma/New-Covariance-Estimator/blob/main/DOASD_Estimation(2)_(2)(1).ipynb
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

"""
=======================================================================
Shrinkage covariance estimation: LedoitWolf vs OAS vs OASD and max-likelihood
=======================================================================

When working with covariance estimation, the usual approach is to use
a maximum likelihood estimator, such as the
:class:`sklearn.covariance.EmpiricalCovariance`. It is unbiased, i.e. it
converges to the true (population) covariance when given many
observations. However, it can also be beneficial to regularize it, in
order to reduce its variance; this, in turn, introduces some bias. This
example illustrates the simple regularization used in
`shrunk_covariance` estimators. In particular, it focuses on how to
set the amount of regularization, i.e. how to choose the bias-variance
trade-off.

Here we compare 3 approaches:

* Setting the parameter by cross-validating the likelihood on three folds
  according to a grid of potential shrinkage parameters.

* A close formula proposed by Ledoit and Wolf to compute
  the asymptotically optimal regularization parameter (minimizing a MSE
  criterion), yielding the :class:`sklearn.covariance.LedoitWolf`
  covariance estimate.

* An improvement of the Ledoit-Wolf shrinkage, the
  :class:`sklearn.covariance.OAS`, proposed by Chen et al. Its
  convergence is significantly better under the assumption that the data
  are Gaussian, in particular for small samples.

To quantify estimation error, we plot the likelihood of unseen data for
different values of the shrinkage parameter. We also show the choices by
cross-validation, or with the LedoitWolf and OAS estimates.

Note that the maximum likelihood estimate corresponds to no shrinkage,
and thus performs poorly. The Ledoit-Wolf estimate performs really well,
as it is close to the optimal and is computational not costly. In this
example, the OAS estimate is a bit further away. Interestingly, both
approaches outperform cross-validation, which is significantly most
computationally costly.


"""

print(__doc__)

import numpy as np
import matplotlib.pyplot as plt
from scipy import linalg

from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance, \
    log_likelihood, empirical_covariance
from sklearn.model_selection import GridSearchCV


# #############################################################################
# Generate sample data
n_features, n_samples = 40, 20
np.random.seed(42)
base_X_train = np.random.normal(size=(n_samples, n_features))
base_X_test = np.random.normal(size=(n_samples, n_features))

# Color samples
coloring_matrix = np.random.normal(size=(n_features, n_features))
X_train = np.dot(base_X_train, coloring_matrix)
X_test = np.dot(base_X_test, coloring_matrix)

# #############################################################################
# Compute the likelihood on test data

# spanning a range of possible shrinkage coefficient values
shrinkages = np.logspace(-2, 0, 30)
negative_logliks = [-ShrunkCovariance(shrinkage=s).fit(X_train).score(X_test)
                    for s in shrinkages]

# under the ground-truth model, which we would not have access to in real
# settings
real_cov = np.dot(coloring_matrix.T, coloring_matrix)
emp_cov = empirical_covariance(X_train)
loglik_real = -log_likelihood(emp_cov, linalg.inv(real_cov))

# #############################################################################
# Compare different approaches to setting the parameter

# GridSearch for an optimal shrinkage coefficient
tuned_parameters = [{'shrinkage': shrinkages}]
cv = GridSearchCV(ShrunkCovariance(), tuned_parameters)
cv.fit(X_train)

# Ledoit-Wolf optimal shrinkage coefficient estimate
lw = LedoitWolf()
loglik_lw = lw.fit(X_train).score(X_test)

# OAS coefficient estimate
oa = OAS()
loglik_oa = oa.fit(X_train).score(X_test)

# #############################################################################
# Plot results
fig = plt.figure()
plt.title("Regularized covariance: likelihood and shrinkage coefficient")
plt.xlabel('Regularization parameter: shrinkage coefficient')
plt.ylabel('Error: negative log-likelihood on test data')
# range shrinkage curve
plt.loglog(shrinkages, negative_logliks, label="Negative log-likelihood")

plt.plot(plt.xlim(), 2 * [loglik_real], '--r',
         label="Real covariance likelihood")

# adjust view
lik_max = np.amax(negative_logliks)
lik_min = np.amin(negative_logliks)
ymin = lik_min - 6. * np.log((plt.ylim()[1] - plt.ylim()[0]))
ymax = lik_max + 10. * np.log(lik_max - lik_min)
xmin = shrinkages[0]
xmax = shrinkages[-1]
# LW likelihood
plt.vlines(lw.shrinkage_, ymin, -loglik_lw, color='magenta',
           linewidth=3, label='Ledoit-Wolf estimate')
# OAS likelihood
plt.vlines(oa.shrinkage_, ymin, -loglik_oa, color='purple',
           linewidth=3, label='OAS estimate')
# best CV estimator likelihood
plt.vlines(cv.best_estimator_.shrinkage, ymin,
           -cv.best_estimator_.score(X_test), color='cyan',
           linewidth=3, label='Cross-validation best estimate')

plt.ylim(ymin, ymax)
plt.xlim(xmin, xmax)
plt.legend()

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance, empirical_covariance

# Generate sample data
n_features, n_samples = 40, 20
np.random.seed(42)
base_X_train = np.random.normal(size=(n_samples, n_features))
base_X_test = np.random.normal(size=(n_samples, n_features))

# Color samples
coloring_matrix = np.random.normal(size=(n_features, n_features))
X_train = np.dot(base_X_train, coloring_matrix)
X_test = np.dot(base_X_test, coloring_matrix)

# Compute the true covariance
true_cov = np.dot(coloring_matrix.T, coloring_matrix)

# Fit covariance estimators
shrunk_cov = ShrunkCovariance().fit(X_train)
lw = LedoitWolf().fit(X_train)
oa = OAS().fit(X_train)
oasd = ShrunkCovariance(shrinkage=0.5).fit(X_train)  # OASD estimator

# Plot results
plt.figure(figsize=(14, 4))

# Plot true covariance
plt.subplot(1, 4, 1)
plt.imshow(true_cov, cmap='viridis', interpolation='nearest')
plt.title('True Covariance')
plt.colorbar()
print("True Covariance:")
print(true_cov)


# Plot Ledoit-Wolf Covariance
plt.subplot(1, 4, 3)
plt.imshow(lw.covariance_, cmap='viridis', interpolation='nearest')
plt.title('Ledoit-Wolf Covariance')
plt.colorbar()
print("Ledoit-Wolf Covariance:")
print(lw.covariance_)

# Plot OAS Covariance
plt.subplot(1, 4, 4)
plt.imshow(oa.covariance_, cmap='viridis', interpolation='nearest')
plt.title('OAS Covariance')
plt.colorbar()
print("OAS Covariance:")
print(oa.covariance_)

# Plot OASD Covariance
plt.subplot(1, 4, 2)
plt.imshow(oasd.covariance_, cmap='viridis', interpolation='nearest')
plt.title('OASD Covariance')
plt.colorbar()
print("OASD Covariance:")
print(oasd.covariance_)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 40  # Number of features
sample_sizes = np.arange(6, 30)  # Sample sizes from 6 to 29

# Define a function to generate sample data with different variable scales
def generate_data(n_samples, n_features):
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.arange(1, n_features + 1)
    X_train = base_X_train * scaling_factors
    return X_train

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': []}
for n_samples in sample_sizes:
    X_train = generate_data(n_samples, n_features)
    for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                      ('OAS', OAS()),
                                      ('OASD', ShrunkCovariance(shrinkage=0.5))]:
        rmse = compute_rmse(estimator, X_train)
        rmse_results[estimator_name].append(rmse)

# Print RMSE values for each estimator across sample sizes
print("RMSE values:")
for estimator_name, rmse_values in rmse_results.items():
    print(f"{estimator_name}: {rmse_values}")

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 40  # Number of features
sample_size = 100  # Sample size
diag_shrinkage_values = np.linspace(0, 1, 20)  # Diagonal shrinkage values from 0 to 1
off_diag_shrinkage_values = np.linspace(0, 1, 20)  # Off-diagonal shrinkage values from 0 to 1

# Generate sample data
np.random.seed(42)
X_train = np.random.normal(size=(sample_size, n_features))

# True covariance matrix (since we're simulating data, we don't have a true covariance, so we'll use the sample covariance)
true_covariance = np.cov(X_train, rowvar=False)

# Function to compute RMSE for diagonal and off-diagonal shrinkage
def compute_shrinkage_rmse(diag_shrinkage, off_diag_shrinkage):
    # Fit ShrunkCovariance estimator with given shrinkage parameters
    estimator = ShrunkCovariance(shrinkage=diag_shrinkage, assume_centered=True)
    estimator.fit(X_train)

    # Compute estimated covariance matrix
    estimated_covariance = estimator.covariance_

    # Compute RMSE for diagonal and off-diagonal shrinkage
    rmse_diag = np.sqrt(mean_squared_error(np.diag(true_covariance), np.diag(estimated_covariance)))
    rmse_off_diag = np.sqrt(mean_squared_error(true_covariance.ravel(), estimated_covariance.ravel()))

    return rmse_diag, rmse_off_diag

# Compute RMSE for each combination of shrinkage parameters
rmse_diag_values = []
rmse_off_diag_values = []
for diag_shrinkage in diag_shrinkage_values:
    for off_diag_shrinkage in off_diag_shrinkage_values:
        rmse_diag, rmse_off_diag = compute_shrinkage_rmse(diag_shrinkage, off_diag_shrinkage)
        rmse_diag_values.append(rmse_diag)
        rmse_off_diag_values.append(rmse_off_diag)

# Reshape RMSE values to match the meshgrid shape
rmse_diag_values = np.array(rmse_diag_values).reshape(len(diag_shrinkage_values), len(off_diag_shrinkage_values))
rmse_off_diag_values = np.array(rmse_off_diag_values).reshape(len(diag_shrinkage_values), len(off_diag_shrinkage_values))

# Plot RMSE for diagonal shrinkage
plt.figure(figsize=(8, 3))
plt.imshow(rmse_diag_values, extent=(0, 1, 1, 0), aspect='auto', cmap='viridis')
plt.colorbar(label='RMSE')
plt.title('RMSE for Diagonal Shrinkage')
plt.xlabel('Off-diagonal Shrinkage')
plt.ylabel('Diagonal Shrinkage')
plt.show()

# Plot RMSE for off-diagonal shrinkage
plt.figure(figsize=(8, 3))
plt.imshow(rmse_off_diag_values, extent=(0, 1, 1, 0), aspect='auto', cmap='viridis')
plt.colorbar(label='RMSE')
plt.title('RMSE for Off-diagonal Shrinkage')
plt.xlabel('Off-diagonal Shrinkage')
plt.ylabel('Diagonal Shrinkage')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import ShrunkCovariance, OAS
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 40  # Number of features
sample_size = 1000  # Sample size
shrinkage_values = np.linspace(0, 1, 20)  # Shrinkage values from 0 to 1

# Generate sample data
np.random.seed(42)
X_train = np.random.normal(size=(sample_size, n_features))

# True covariance matrix (since we're simulating data, we don't have a true covariance, so we'll use the sample covariance)
true_covariance = np.cov(X_train, rowvar=False)

# Function to compute RMSE for shrinkage parameter
def compute_shrinkage_rmse(shrinkage):
    # Fit ShrunkCovariance estimator with given shrinkage parameter
    estimator = ShrunkCovariance(shrinkage=shrinkage, assume_centered=True)
    estimator.fit(X_train)

    # Compute estimated covariance matrix
    estimated_covariance = estimator.covariance_

    # Compute RMSE for shrinkage parameter
    rmse = np.sqrt(mean_squared_error(true_covariance.ravel(), estimated_covariance.ravel()))

    return rmse

# Compute RMSE for each shrinkage value
rmse_values = []
for shrinkage in shrinkage_values:
    rmse = compute_shrinkage_rmse(shrinkage)
    rmse_values.append(rmse)

# Plot RMSE for shrinkage parameter
plt.figure(figsize=(8, 3))
plt.plot(shrinkage_values, rmse_values, marker='o', linestyle='-')
plt.title('RMSE for Shrinkage Parameter (ShrunkCovariance)')
plt.xlabel('Shrinkage Parameter')
plt.ylabel('RMSE')
plt.grid(True)
plt.show()

# Now, let's compare the performance of DOASD with OASD
# Define the DOASD estimator class with adaptive shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit DOASD estimator with default parameters
doasd_estimator = DOASD()
doasd_estimator.fit(X_train)

# Fit OASD estimator
oasd_estimator = OAS(assume_centered=True)
oasd_estimator.fit(X_train)

# Compute RMSE for DOASD
rmse_doasd = np.sqrt(mean_squared_error(true_covariance.ravel(), doasd_estimator.covariance_.ravel()))

# Compute RMSE for OASD
rmse_oasd = np.sqrt(mean_squared_error(true_covariance.ravel(), oasd_estimator.covariance_.ravel()))

# Plot performance comparison
plt.figure(figsize=(8, 3))
plt.bar(['DOASD', 'OASD'], [rmse_doasd, rmse_oasd], color=['blue', 'green'])
plt.title('Performance Comparison: DOASD vs OASD')
plt.xlabel('Estimator')
plt.ylabel('RMSE')
plt.grid(axis='y')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 40  # Number of features
sample_sizes = np.arange(6, 36)  # Sample sizes from 6 to 30

# Define a function to generate sample data with different variable scales
def generate_data(n_samples, n_features):
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.arange(1, n_features + 1)
    X_train = base_X_train * scaling_factors
    return X_train

# Define a function to compute RMSE for the DOASD estimator
def compute_rmse(X_train):
    true_cov = np.cov(X_train, rowvar=False)
    emp_cov = np.cov(X_train, rowvar=False)

    # Compute shrinkage parameters
    n_samples = X_train.shape[0]
    diag_shrinkage = 1 - (n_features + 1) / n_samples
    off_diag_shrinkage = 1 - np.sum(np.diag(emp_cov)) / np.sum(emp_cov)

    # Apply shrinkage
    shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
    shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

    # Compute RMSE
    rmse = np.sqrt(mean_squared_error(true_cov.ravel(), shrunk_cov.ravel()))
    return rmse

# Fit DOASD estimator for different sample sizes and compute RMSE
rmse_values = []
for n_samples in sample_sizes:
    X_train = generate_data(n_samples, n_features)
    rmse = compute_rmse(X_train)
    rmse_values.append(rmse)

# Print RMSE values for DOASD estimator across sample sizes
print("RMSE values for DOASD estimator:", rmse_values)

# Plot RMSE of DOASD estimator across sample sizes
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_values, label='DOASD', color='blue')
plt.title('RMSE of DOASD Estimator Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

class DOASD:
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def fit(self, X):
        emp_cov = np.cov(X, rowvar=False)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply adaptive shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Parameters
n_features = 40
n_samples = 1000

# Generate sample data
X_train = np.random.normal(size=(n_samples, n_features))

# Create DOASD estimator
doasd_estimator = DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1)

# Fit DOASD estimator to data
doasd_estimator.fit(X_train)

# Plot original covariance matrix
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(np.cov(X_train, rowvar=False), cmap='hot', interpolation='nearest')
plt.title('Original Covariance Matrix')
plt.colorbar()

# Plot shrunk covariance matrix
plt.subplot(1, 2, 2)
plt.imshow(doasd_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('Shrunk Covariance Matrix (DOASD)')
plt.colorbar()

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

class DOASD:
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def fit(self, X):
        emp_cov = np.cov(X, rowvar=False)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply adaptive shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Parameters
n_features = 40
n_samples = 1000

# Generate sample data
X_train = np.random.normal(size=(n_samples, n_features))

# Create DOASD estimator
doasd_estimator = DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1)

# Fit DOASD estimator to data
doasd_estimator.fit(X_train)

# Create other estimators
oasd_estimator = ShrunkCovariance(shrinkage=0.5)
oas_estimator = OAS()
lw_estimator = LedoitWolf()

# Fit other estimators to data
oasd_estimator.fit(X_train)
oas_estimator.fit(X_train)
lw_estimator.fit(X_train)

# Plot original covariance matrix
plt.figure(figsize=(15, 5))
plt.subplot(1, 4, 1)
plt.imshow(np.cov(X_train, rowvar=False), cmap='hot', interpolation='nearest')
plt.title('Original Covariance Matrix')
plt.colorbar()

# Plot shrunk covariance matrices
plt.subplot(1, 4, 2)
plt.imshow(doasd_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('DOASD')
plt.colorbar()

plt.subplot(1, 4, 3)
plt.imshow(oasd_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('OASD')
plt.colorbar()

plt.subplot(1, 4, 4)
plt.imshow(lw_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('Ledoit-Wolf')
plt.colorbar()

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with different variable scales
def generate_data(n_samples, n_features):
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.arange(1, n_features + 1)
    X_train = base_X_train * scaling_factors
    return X_train

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    X_train = generate_data(n_samples, n_features)
    for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                      ('OAS', OAS()),
                                      ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                      ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
        rmse = compute_rmse(estimator, X_train)
        rmse_results[estimator_name].append(rmse)

# Print RMSE values for each estimator across sample sizes
print("RMSE values:")
for estimator_name, rmse_values in rmse_results.items():
    print(f"{estimator_name}: {rmse_values}")

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(10, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with different variable scales
def generate_data(n_samples, n_features):
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.arange(1, n_features + 1)
    X_train = base_X_train * scaling_factors
    return X_train

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    X_train = generate_data(n_samples, n_features)
    for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                      ('OAS', OAS()),
                                      ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                      ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
        rmse = compute_rmse(estimator, X_train)
        rmse_results[estimator_name].append(rmse)

# Normalize RMSE values to be between 0 and 1
max_rmse = max(max(rmse_values) for rmse_values in rmse_results.values())
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = [rmse / max_rmse for rmse in rmse_values]

# Print RMSE values for each estimator across sample sizes
print("Normalized RMSE values:")
for estimator_name, rmse_values in rmse_results.items():
    print(f"{estimator_name}: {rmse_values}")

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name)

plt.title('Normalized RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('Normalized RMSE')
plt.legend()
plt.grid(True)
plt.ylim(0, 1)  # Ensure y-axis limits between 0 and 1
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(6, 31)  # Sample sizes from 6 to 30
shrinkage_values = np.linspace(0, 1, 11)  # Shrinkage parameter values from 0 to 1

# Define a function to generate sample data with different variable scales
def generate_data(n_samples, n_features):
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.arange(1, n_features + 1)
    X_train = base_X_train * scaling_factors
    return X_train

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and shrinkage parameters and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for shrinkage in shrinkage_values:
    for n_samples in sample_sizes:
        X_train = generate_data(n_samples, n_features)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=shrinkage)),
                                          ('DOASD', DOASD(diagonal_shrinkage=shrinkage, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_values = np.array(rmse_values).reshape(len(shrinkage_values), len(sample_sizes))
    max_rmse = np.max(rmse_values)  # Maximum RMSE across all shrinkage values
    rmse_results[estimator_name] = rmse_values / max_rmse  # Normalize RMSE to be between 0 and 1

# Plot RMSE against shrinkage values for each estimator with shaded error bands
plt.figure(figsize=(12, 8))
for estimator_name, rmse_values in rmse_results.items():
    mean_rmse = rmse_values.mean(axis=1)
    std_rmse = rmse_values.std(axis=1)
    plt.plot(shrinkage_values, mean_rmse, label=estimator_name)
    plt.fill_between(shrinkage_values, mean_rmse - std_rmse, mean_rmse + std_rmse, alpha=0.2)
plt.title('RMSE of Covariance Estimators Against Shrinkage Values (Normalized)')
plt.xlabel('Shrinkage')
plt.ylabel('Mean RMSE Across Sample Sizes (Normalized)')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with different variable scales
def generate_data(n_samples, n_features, sd):
    Lambda = np.diag(np.ones(n_features) * sd)
    Γ = np.eye(n_features)  # Identity matrix for simplicity
    Σ = np.dot(np.dot(Lambda, Γ), Lambda.T)
    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)
    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        X_train = generate_data(n_samples, n_features, sd)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                          ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with heteroscedasticity
def generate_data_heteroscedastic(n_samples, n_features, sd):
    Lambda = np.diag(np.arange(1, n_features + 1) * sd)  # Varying diagonal elements
    Γ = np.eye(n_features)  # Identity matrix for simplicity
    Σ = np.dot(np.dot(Lambda, Γ), Lambda.T)
    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)
    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        X_train = generate_data_heteroscedastic(n_samples, n_features, sd)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                          ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with non-linear relationships
def generate_data_non_linear(n_samples, n_features, sd):
    Lambda = np.diag(np.ones(n_features) * sd)
    Γ = np.eye(n_features) + 0.1 * np.random.randn(n_features, n_features)  # Add small noise to the identity matrix
    Σ = np.dot(np.dot(Lambda, Γ), Lambda.T)
    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)
    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        X_train = generate_data_non_linear(n_samples, n_features, sd)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                          ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with a complex correlation structure
def generate_data_complex_correlation(n_samples, n_features, sd):
    Lambda = np.diag(np.ones(n_features) * sd)
    cluster_size = n_features // 5  # Divide features into 5 clusters
    Γ = np.eye(n_features) + 0.3 * np.random.randn(n_features, n_features)  # Add noise to the identity matrix
    for i in range(5):
        start_idx = i * cluster_size
        end_idx = (i + 1) * cluster_size
        Γ[start_idx:end_idx, start_idx:end_idx] += 0.6  # Add higher correlation within clusters
    Σ = np.dot(np.dot(Lambda, Γ), Lambda.T)
    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)
    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        X_train = generate_data_complex_correlation(n_samples, n_features, sd)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                          ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100

# Define a function to generate sample data with different variable scales
def generate_data_with_outliers(n_samples, n_features, sd, outlier_frac=0.05):
    Lambda = np.diag(np.ones(n_features) * sd)
    Γ = np.eye(n_features)  # Identity matrix for simplicity
    Σ = np.dot(np.dot(Lambda, Γ), Lambda.T)

    # Generate data without outliers
    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)

    # Introduce outliers
    num_outliers = int(n_samples * outlier_frac)
    outlier_indices = np.random.choice(n_samples, num_outliers, replace=False)
    data[outlier_indices] = np.random.multivariate_normal(mean=np.zeros(n_features), cov=10 * Σ, size=num_outliers)

    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        X_train = generate_data_with_outliers(n_samples, n_features, sd)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                          ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100
n_clusters = 5  # Number of clusters
cluster_size = n_features // n_clusters  # Number of features per cluster

# Define a function to generate sample data with complex correlation structure
def generate_data(n_samples, n_features, sd):
    Lambda = np.diag(np.ones(n_features) * sd)
    Γ = np.eye(n_features)  # Identity matrix for simplicity

    # Generate cluster-wise correlation structure
    cluster_correlation = 0.2  # Correlation within clusters
    Σ = np.zeros((n_features, n_features))
    for i in range(n_clusters):
        start_idx = i * cluster_size
        end_idx = (i + 1) * cluster_size
        cluster_covariance = np.ones((cluster_size, cluster_size)) * cluster_correlation
        np.fill_diagonal(cluster_covariance, 1)
        Σ[start_idx:end_idx, start_idx:end_idx] = cluster_covariance

    Σ = np.dot(np.dot(Lambda, Σ), Lambda.T)
    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)
    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        X_train = generate_data(n_samples, n_features, sd)
        for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                          ('OAS', OAS()),
                                          ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                          ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
            rmse = compute_rmse(estimator, X_train)
            rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 100
n_clusters = 3  # Number of clusters
cluster_size = n_features // n_clusters  # Number of features per cluster

# Define a function to generate sample data with different variable scales and cluster-wise correlation
def generate_data(n_samples, n_features, sd, cluster_correlation):
    Lambda = np.diag(np.ones(n_features) * sd)
    Γ = np.eye(n_features)  # Identity matrix for simplicity
    Σ = np.dot(np.dot(Lambda, Γ), Lambda.T)

    # Generate cluster-wise correlation structure
    Σ = np.zeros((n_features, n_features))
    for i in range(n_clusters):
        start_idx = i * cluster_size
        end_idx = (i + 1) * cluster_size
        cluster_covariance = np.ones((cluster_size, cluster_size)) * cluster_correlation
        np.fill_diagonal(cluster_covariance, 1)
        Σ[start_idx:end_idx, start_idx:end_idx] = cluster_covariance

    data = np.random.multivariate_normal(mean=np.zeros(n_features), cov=Σ, size=n_samples)
    return data

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': []}
for n_samples in sample_sizes:
    for sd in range(1, 21):
        for cluster_correlation in [0.1, 0.3, 0.5]:  # Vary the cluster-wise correlation
            X_train = generate_data(n_samples, n_features, sd, cluster_correlation)
            for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                              ('OAS', OAS()),
                                              ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                              ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1))]:
                rmse = compute_rmse(estimator, X_train)
                rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(10, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=100, noise=0.2, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, 2, n_features)  # Linearly increasing scaling factors
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements
    X_train = base_X_train * scaling_factors
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
    return X_train

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 300 to 999

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.5):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Adjust off_diagonal_shrinkage based on delta_off_diag
        if off_diag_shrinkage == 0.5:  # If delta_off_diag is 0.0, set off_diagonal_shrinkage to 0.6 (to match OASD)
            off_diagonal_shrinkage = 0.6
        elif off_diag_shrinkage <= 0.5:  # If delta_off_diag <= 0.5, set off_diagonal_shrinkage to a lower value
            off_diagonal_shrinkage = 0.2
        else:  # If delta_off_diag > 0.5, set off_diagonal_shrinkage to 0.8
            off_diagonal_shrinkage = 0.8

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.5):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        # Compute sample covariance matrix
        sample_cov = np.cov(X, rowvar=False)

        # Decompose into diagonal and off-diagonal components
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        # Compute shrinkage targets
        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        # Apply shrinkage
        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        # Reconstruct covariance matrix
        self.covariance_ = shrunk_diag + shrunk_off_diag

        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for n_samples in sample_sizes:
    X_train = make_data_with_variance(n_samples, n_features)
    for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                      ('OAS', OAS()),
                                      ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                      ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.5)),  # Set off_diagonal_shrinkage = 0.5
                                      ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.5, delta_off_diag=0.5))]:
        rmse = compute_rmse(estimator, X_train)
        rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

print(__doc__)

import numpy as np
import matplotlib.pyplot as plt
from scipy import linalg

from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance, \
    log_likelihood, empirical_covariance


# #############################################################################
# Generate sample data
n_features, n_samples = 40, 20
np.random.seed(42)
base_X_train = np.random.normal(size=(n_samples, n_features))
base_X_test = np.random.normal(size=(n_samples, n_features))

# Color samples
coloring_matrix = np.random.normal(size=(n_features, n_features))
X_train = np.dot(base_X_train, coloring_matrix)
X_test = np.dot(base_X_test, coloring_matrix)

# #############################################################################
# Compute the likelihood on test data

# spanning a range of possible shrinkage coefficient values
shrinkages = np.logspace(-2, 0, 30)
negative_logliks = [-ShrunkCovariance(shrinkage=s).fit(X_train).score(X_test)
                    for s in shrinkages]

# under the ground-truth model, which we would not have access to in real
# settings
real_cov = np.dot(coloring_matrix.T, coloring_matrix)
emp_cov = empirical_covariance(X_train)
loglik_real = -log_likelihood(emp_cov, linalg.inv(real_cov))

# #############################################################################
# Compare different approaches to setting the parameter

# Ledoit-Wolf optimal shrinkage coefficient estimate
lw = LedoitWolf()
loglik_lw = lw.fit(X_train).score(X_test)

# OAS coefficient estimate
oa = OAS()
loglik_oa = oa.fit(X_train).score(X_test)

# #############################################################################
# Plot results
fig = plt.figure()
plt.title("Regularized covariance: likelihood and shrinkage coefficient")
plt.xlabel('Regularization parameter: shrinkage coefficient')
plt.ylabel('Error: negative log-likelihood on test data')
# range shrinkage curve
plt.loglog(shrinkages, negative_logliks, label="Negative log-likelihood")

plt.plot(plt.xlim(), 2 * [loglik_real], '--r',
         label="Real covariance likelihood")

# adjust view
lik_max = np.amax(negative_logliks)
lik_min = np.amin(negative_logliks)
ymin = lik_min - 6. * np.log((plt.ylim()[1] - plt.ylim()[0]))
ymax = lik_max + 10. * np.log(lik_max - lik_min)
xmin = shrinkages[0]
xmax = shrinkages[-1]
# LW likelihood
plt.vlines(lw.shrinkage_, ymin, -loglik_lw, color='magenta',
           linewidth=3, label='Ledoit-Wolf estimate')
# OAS likelihood
plt.vlines(oa.shrinkage_, ymin, -loglik_oa, color='purple',
           linewidth=3, label='OAS estimate')

plt.ylim(ymin, ymax)
plt.xlim(xmin, xmax)
plt.legend()

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy import linalg
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance, log_likelihood, empirical_covariance

# #############################################################################
# Generate sample data
n_features, n_samples = 40, 20
np.random.seed(42)
base_X_train = np.random.normal(size=(n_samples, n_features))
base_X_test = np.random.normal(size=(n_samples, n_features))

# Color samples
coloring_matrix = np.random.normal(size=(n_features, n_features))
X_train = np.dot(base_X_train, coloring_matrix)
X_test = np.dot(base_X_test, coloring_matrix)

# #############################################################################
# Compute the likelihood on test data

# Spanning a range of possible shrinkage coefficient values
shrinkages = np.logspace(-2, 0, 50)
negative_logliks = [-ShrunkCovariance(shrinkage=s).fit(X_train).score(X_test)
                    for s in shrinkages]

# Under the ground-truth model, which we would not have access to in real settings
real_cov = np.dot(coloring_matrix.T, coloring_matrix)
emp_cov = empirical_covariance(X_train)
loglik_real = -log_likelihood(emp_cov, linalg.inv(real_cov))

# #############################################################################
# Compare different approaches to setting the parameter

# Ledoit-Wolf optimal shrinkage coefficient estimate
lw = LedoitWolf()
loglik_lw = lw.fit(X_train).score(X_test)

# OAS coefficient estimate
oa = OAS()
loglik_oa = oa.fit(X_train).score(X_test)

# #############################################################################
# Plot results
fig = plt.figure()
plt.title("Regularized covariance: likelihood and shrinkage coefficient")
plt.xlabel('Regularization parameter: shrinkage coefficient')
plt.ylabel('Error: negative log-likelihood on test data')

# Range shrinkage curve
plt.loglog(shrinkages, negative_logliks, label="Negative log-likelihood")

# Real covariance likelihood
plt.plot(plt.xlim(), 2 * [loglik_real], '--r', label="Real covariance likelihood")

# Adjust view
lik_max = np.amax(negative_logliks)
lik_min = np.amin(negative_logliks)
ymin = lik_min - 6. * np.log((plt.ylim()[1] - plt.ylim()[0]))
ymax = lik_max + 10. * np.log(lik_max - lik_min)
xmin = shrinkages[0]
xmax = shrinkages[-1]

# Ledoit-Wolf likelihood
plt.vlines(lw.shrinkage_, ymin, -loglik_lw, color='magenta', linewidth=3, label='Ledoit-Wolf estimate')

# OAS likelihood
plt.vlines(oa.shrinkage_, ymin, -loglik_oa, color='purple', linewidth=3, label='OAS estimate')

# Shrinkage parameters comparison
plt.vlines(0.6, ymin, ymax, color='yellow', linewidth= 3 , label='DOASD Diagonal Shrinkage')
plt.vlines(0.4, ymin, ymax, color='green', linewidth= 3, label='DOASD Off-diagonal Shrinkage')

plt.ylim(ymin, ymax)
plt.xlim(xmin, xmax)
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from scipy import linalg
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance, log_likelihood, empirical_covariance

# #############################################################################
# Generate sample data
n_features, n_samples = 40, 20
np.random.seed(42)
base_X_train = np.random.normal(size=(n_samples, n_features))
base_X_test = np.random.normal(size=(n_samples, n_features))

# Color samples
coloring_matrix = np.random.normal(size=(n_features, n_features))
X_train = np.dot(base_X_train, coloring_matrix)
X_test = np.dot(base_X_test, coloring_matrix)

# #############################################################################
# Compute the likelihood on test data

# Spanning a range of possible shrinkage coefficient values
shrinkages = np.logspace(-2, 0, 50)
negative_logliks = [-ShrunkCovariance(shrinkage=s).fit(X_train).score(X_test)
                    for s in shrinkages]

# Under the ground-truth model, which we would not have access to in real settings
real_cov = np.dot(coloring_matrix.T, coloring_matrix)
emp_cov = empirical_covariance(X_train)
loglik_real = -log_likelihood(emp_cov, linalg.inv(real_cov))

# #############################################################################
# Compare different approaches to setting the parameter

# Ledoit-Wolf optimal shrinkage coefficient estimate
lw = LedoitWolf()
loglik_lw = lw.fit(X_train).score(X_test)

# OAS coefficient estimate
oa = OAS()
loglik_oa = oa.fit(X_train).score(X_test)

# #############################################################################
# Plot results
fig = plt.figure()
plt.title("Regularized covariance: likelihood and shrinkage coefficient")
plt.xlabel('Regularization parameter: shrinkage coefficient')
plt.ylabel('Error: negative log-likelihood on test data')

# Range shrinkage curve
plt.loglog(shrinkages, negative_logliks, label="Negative log-likelihood")

# Real covariance likelihood
plt.plot(plt.xlim(), 2 * [loglik_real], '--r', label="Real covariance likelihood")

# Adjust view
lik_max = np.amax(negative_logliks)
lik_min = np.amin(negative_logliks)
ymin = lik_min - 6. * np.log((plt.ylim()[1] - plt.ylim()[0]))
ymax = lik_max + 10. * np.log(lik_max - lik_min)
xmin = shrinkages[0]
xmax = shrinkages[-1]

# Ledoit-Wolf likelihood
plt.vlines(lw.shrinkage_, ymin, -loglik_lw, color='magenta', linewidth=3, label='Ledoit-Wolf estimate')

# OAS likelihood
plt.vlines(oa.shrinkage_, ymin, -loglik_oa, color='purple', linewidth=3, label='OAS estimate')

# Shrinkage parameters comparison
plt.vlines(0.4, ymin, ymax, color='yellow', linewidth= 3 , label='DOASD Diagonal Shrinkage')
plt.vlines(0.6, ymin, ymax, color='green', linewidth= 3, label='DOASD Off-diagonal Shrinkage')

# Dual Shrinkage parameters
plt.vlines(0.4, ymin, ymax, color='blue', linestyle='--', linewidth=3, label='Dual Shrinkage Diagonal Shrinkage')
plt.vlines(0.6, ymin, ymax, color='orange', linestyle='--', linewidth=3, label='Dual Shrinkage Off-diagonal Shrinkage')

plt.ylim(ymin, ymax)
plt.xlim(xmin, xmax)
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

class DOASD:
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1):
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def fit(self, X):
        emp_cov = np.cov(X, rowvar=False)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Apply adaptive shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diag_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diag_shrinkage

        self.covariance_ = shrunk_cov
        return self
.0
# Parameters
n_features = 40
n_samples = 1000

# Generate sample data
X_train = np.random.normal(size=(n_samples, n_features))

# Create DOASD estimator
doasd_estimator = DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.1)

# Fit DOASD estimator to data
doasd_estimator.fit(X_train)

# Create other estimators
oasd_estimator = ShrunkCovariance(shrinkage=0.5)
oas_estimator = OAS()
lw_estimator = LedoitWolf()

# Fit other estimators to data
oasd_estimator.fit(X_train)
oas_estimator.fit(X_train)
lw_estimator.fit(X_train)

# Dual Shrinkage estimator
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.1):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        # Compute sample covariance matrix
        sample_cov = np.cov(X, rowvar=False)

        # Decompose into diagonal and off-diagonal components
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        # Compute shrinkage targets
        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        # Apply shrinkage
        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        # Reconstruct covariance matrix
        self.covariance_ = shrunk_diag + shrunk_off_diag

        return self

dual_shrinkage_estimator = DualShrinkageEstimator(delta_diag=0.5, delta_off_diag=0.1)
dual_shrinkage_estimator.fit(X_train)

# Plot original covariance matrix
plt.figure(figsize=(20, 5))
plt.subplot(1, 5, 1)
plt.imshow(np.cov(X_train, rowvar=False), cmap='hot', interpolation='nearest')
plt.title('Original Covariance Matrix')
plt.colorbar()

# Plot shrunk covariance matrices
plt.subplot(1, 5, 2)
plt.imshow(doasd_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('DOASD')
plt.colorbar()

plt.subplot(1, 5, 3)
plt.imshow(oasd_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('OASD')
plt.colorbar()

plt.subplot(1, 5, 4)
plt.imshow(lw_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('Ledoit-Wolf')
plt.colorbar()

plt.subplot(1, 5, 5)
plt.imshow(dual_shrinkage_estimator.covariance_, cmap='hot', interpolation='nearest')
plt.title('Dual Shrinkage')
plt.colorbar()

plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Function to create a dataset with varying diagonal elements and outliers
def make_data_with_variance_and_outliers(n_samples=100, n_features=100, noise=0.2, n_outliers=10, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples - n_outliers, n_features))
    scaling_factors = np.linspace(1, 2, n_features)  # Linearly increasing scaling factors
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements
    X_train = base_X_train * scaling_factors
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    # Add outliers
    outlier_indices = random_state.choice(range(n_samples - n_outliers), size=n_outliers, replace=False)
    outliers = random_state.normal(size=(n_outliers, n_features)) * 10  # Outliers are larger
    X_train[outlier_indices] = outliers

    return X_train

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(30, 100)  # Sample sizes from 30 to 99

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.5):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Adjust off_diagonal_shrinkage based on delta_off_diag
        if off_diag_shrinkage == 0.5:  # If delta_off_diag is 0.0, set off_diagonal_shrinkage to 0.6 (to match OASD)
            off_diagonal_shrinkage = 0.6
        elif off_diag_shrinkage <= 0.5:  # If delta_off_diag <= 0.5, set off_diagonal_shrinkage to a lower value
            off_diagonal_shrinkage = 0.2
        else:  # If delta_off_diag > 0.5, set off_diagonal_shrinkage to 0.8
            off_diagonal_shrinkage = 0.8

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.5):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        # Compute sample covariance matrix
        sample_cov = np.cov(X, rowvar=False)

        # Decompose into diagonal and off-diagonal components
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        # Compute shrinkage targets
        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        # Apply shrinkage
        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        # Reconstruct covariance matrix
        self.covariance_ = shrunk_diag + shrunk_off_diag

        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for n_samples in sample_sizes:
    X_train = make_data_with_variance_and_outliers(n_samples, n_features, random_state=42)
    for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                      ('OAS', OAS()),
                                      ('OASD', ShrunkCovariance(shrinkage=0.5)),
                                      ('DOASD', DOASD(diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.5)),  # Set off_diagonal_shrinkage = 0.5
                                      ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.5, delta_off_diag=0.5))]:
        rmse = compute_rmse(estimator, X_train)
        rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes with Outliers')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance
from sklearn.metrics import mean_squared_error

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=100, noise=0.2, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, 2, n_features)  # Linearly increasing scaling factors
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements
    X_train = base_X_train * scaling_factors
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
    return X_train

# Parameters
n_features = 1000  # Number of features
sample_sizes = np.arange(300, 1000)  # Sample sizes from 30 to 99

# Define a function to compute RMSE for a given estimator and sample size
def compute_rmse(estimator, X_train):
    true_cov = np.cov(X_train, rowvar=False)
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    return np.sqrt(mean_squared_error(true_cov.ravel(), estimated_cov.ravel()))

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.5, off_diagonal_shrinkage=0.5):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        # Calculate the empirical covariance of X
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Compute shrinkage factors
        diag_shrinkage = self.diagonal_shrinkage
        off_diag_shrinkage = self.off_diagonal_shrinkage

        # Adjust off_diagonal_shrinkage based on delta_off_diag
        if off_diag_shrinkage == 0.5:  # If delta_off_diag is 0.0, set off_diagonal_shrinkage to 0.6 (to match OASD)
            off_diagonal_shrinkage = 0.6
        elif off_diag_shrinkage <= 0.5:  # If delta_off_diag <= 0.5, set off_diagonal_shrinkage to a lower value
            off_diagonal_shrinkage = 0.2
        else:  # If delta_off_diag > 0.5, set off_diagonal_shrinkage to 0.8
            off_diagonal_shrinkage = 0.8

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - diag_shrinkage) + np.diag(np.diag(emp_cov)) * diag_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.5):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        # Compute sample covariance matrix
        sample_cov = np.cov(X, rowvar=False)

        # Decompose into diagonal and off-diagonal components
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        # Compute shrinkage targets
        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        # Apply shrinkage
        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        # Reconstruct covariance matrix
        self.covariance_ = shrunk_diag + shrunk_off_diag

        return self

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for n_samples in sample_sizes:
    X_train = make_data_with_variance(n_samples, n_features, random_state=42)
    for estimator_name, estimator in [('Ledoit-Wolf', LedoitWolf()),
                                      ('OAS', OAS()),
                                      ('OASD', ShrunkCovariance(shrinkage=0.4)),
                                      ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),  # Set off_diagonal_shrinkage = 0.5
                                      ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))]:
        rmse = compute_rmse(estimator, X_train)
        rmse_results[estimator_name].append(rmse)

# Reshape RMSE values for plotting
for estimator_name, rmse_values in rmse_results.items():
    rmse_results[estimator_name] = np.array(rmse_values).reshape(len(sample_sizes), -1)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values.mean(axis=1), label=estimator_name)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=100, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_features = 100  # Number of features
sample_sizes = np.arange(300, 1000, 100)  # Sample sizes

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=5000):
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Fit covariance estimators for different sample sizes and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for n_samples in sample_sizes:
    X_train = make_data_with_variance(n_samples, n_features, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(sample_sizes, prial_values, label=estimator_name)

plt.title('PRIAL of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=100, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.5):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 500  # Fixed number of samples
n_features = 100  # Number of features
sd_values = np.arange(1, 21, 2)  # Range of sd values

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=500):
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Fit covariance estimators for different sd values and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across sd values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(sd_values, prial_values, label=estimator_name)

plt.title('PRIAL of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements
def make_data_with_variance(n_samples=50, n_features=100, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)     # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=5000):
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Function to compute average correlation
def compute_average_correlation(estimator, X_train):
    estimator.fit(X_train)
    estimated_cov = estimator.covariance_
    corr_matrix = np.corrcoef(estimated_cov)
    avg_corr = (np.sum(np.abs(corr_matrix)) - np.trace(corr_matrix)) / (corr_matrix.shape[0] * (corr_matrix.shape[1] - 1))
    return avg_corr

# Parameters
n_samples = 50  # Number of samples (lower than number of features)
n_features = 100  # Number of features
sd_values = np.arange(1, 21)  # Standard deviation values

# Fit covariance estimators for different sd values and compute PRIAL and average correlation
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
avg_corr_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}

for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train)
        avg_corr = compute_average_correlation(estimator, X_train)

        prial_results[estimator_name].append(prial)
        avg_corr_results[estimator_name].append(avg_corr)

# Plot PRIAL and average correlation across sd values for each estimator
plt.figure(figsize=(14, 6))

# Plot PRIAL
plt.subplot(1, 2, 1)
for estimator_name, prial_values in prial_results.items():
    plt.plot(sd_values, prial_values, label=estimator_name)

plt.title('PRIAL of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)

# Plot Average Correlation
plt.subplot(1, 2, 2)
for estimator_name, avg_corr_values in avg_corr_results.items():
    plt.plot(sd_values, avg_corr_values, label=estimator_name)

plt.title('Average Correlation of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('Average Correlation')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=100, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.3, off_diagonal_shrinkage=0.4):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.3, delta_off_diag=0.4):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 100  # Fixed number of samples
n_features = 500  # Number of features
sd_values = np.linspace(1, 20, 20)  # Smooth range of sd values

# Function to compute average correlation coefficient
def compute_avg_correlation(estimator, X_train):
    estimator.fit(X_train)
    cov_matrix = estimator.covariance_
    corr_matrix = np.corrcoef(cov_matrix)
    avg_correlation = np.mean(corr_matrix[np.triu_indices_from(corr_matrix, k=1)])
    return avg_correlation

# Fit covariance estimators for different sd values and compute average correlation coefficient
corr_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.3)),
        ('DOASD', DOASD(diagonal_shrinkage=0.3, off_diagonal_shrinkage=0.4)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.3, delta_off_diag=0.4))
    ]:
        avg_corr = compute_avg_correlation(estimator, X_train)
        corr_results[estimator_name].append(avg_corr)

# Plot average correlation coefficient across sd values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, corr_values in corr_results.items():
    plt.plot(sd_values, corr_values, label=estimator_name)

plt.title('Average Correlation Coefficient of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('Average Correlation Coefficient (ρ)')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=100, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.3, off_diagonal_shrinkage=0.4):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.3, delta_off_diag=0.4):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 100  # Fixed number of samples
n_features = 500  # Number of features
sd_values = np.linspace(1, 20, 20)  # Smooth range of sd values

# Function to compute average correlation coefficient
def compute_avg_correlation(estimator, X_train):
    estimator.fit(X_train)
    cov_matrix = estimator.covariance_
    corr_matrix = np.corrcoef(cov_matrix)
    avg_correlation = np.mean(corr_matrix[np.triu_indices_from(corr_matrix, k=1)])
    return avg_correlation

# Fit covariance estimators for different sd values and compute average correlation coefficient
corr_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.3)),
        ('DOASD', DOASD(diagonal_shrinkage=0.3, off_diagonal_shrinkage=0.4)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.3, delta_off_diag=0.4))
    ]:
        avg_corr = compute_avg_correlation(estimator, X_train)
        corr_results[estimator_name].append(avg_corr)

# Plot average correlation coefficient across sd values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, corr_values in corr_results.items():
    plt.plot(sd_values, corr_values, label=estimator_name)

plt.title('Average Correlation Coefficient of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('Average Correlation Coefficient (ρ)')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=500, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.5):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 100  # Number of samples
n_features = 500  # Number of features
sd_values = np.arange(1, 21, 2)  # Range of sd values

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=500):
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Fit covariance estimators for different sd values and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across sd values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(sd_values, prial_values, label=estimator_name)

plt.title('PRIAL of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()



import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=500, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.5, delta_off_diag=0.5):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute PRIAL for the inverse covariance matrix for a given estimator
def compute_prial_inv(estimator, X_train, B=500):
    n_samples, n_features = X_train.shape
    true_cov_inv = np.linalg.inv(np.cov(X_train, rowvar=False))
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov_inv = np.linalg.inv(np.cov(bootstrap_sample, rowvar=False))
        estimator.fit(bootstrap_sample)
        estimated_cov_inv = np.linalg.inv(estimator.covariance_)

        sample_cov_list.append(sample_cov_inv)
        estimated_cov_list.append(estimated_cov_inv)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])

    prial_inv = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial_inv

# Parameters
n_samples = 100  # Number of samples
n_features = 500  # Number of features
sd_values = np.arange(1, 21, 2)  # Range of sd values

# Fit covariance estimators for different sd values and compute PRIAL
prial_results_sd = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial_inv = compute_prial_inv(estimator, X_train)
        prial_results_sd[estimator_name].append(prial_inv)

# Plot PRIAL across sd values for each estimator
plt.figure(figsize=(8, 6))

# Subplot for PRIAL across sd values
for estimator_name, prial_values in prial_results_sd.items():
    plt.plot(sd_values, prial_values, label=estimator_name)
plt.title(r'$\mathrm{PRIAL^{INV}}$ of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel(r'$\mathrm{PRIAL^{INV}}$')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=500, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute PRIAL for the inverse covariance matrix for a given estimator
def compute_prial_inv(estimator, X_train, B=500):
    n_samples, n_features = X_train.shape
    true_cov_inv = np.linalg.inv(np.cov(X_train, rowvar=False))
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov_inv = np.linalg.inv(np.cov(bootstrap_sample, rowvar=False))
        estimator.fit(bootstrap_sample)
        estimated_cov_inv = np.linalg.inv(estimator.covariance_)

        sample_cov_list.append(sample_cov_inv)
        estimated_cov_list.append(estimated_cov_inv)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])

    prial_inv = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial_inv

# Parameters
n_samples = 100  # Number of samples
n_features = 500  # Number of features
sd_values = np.arange(1, 21, 2)  # Range of sd values

# Fit covariance estimators for different sd values and compute PRIAL
prial_results_sd = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial_inv = compute_prial_inv(estimator, X_train)
        prial_results_sd[estimator_name].append(prial_inv)

# Plot PRIAL across sd values for each estimator
plt.figure(figsize=(8, 6))

# Subplot for PRIAL across sd values
for estimator_name, prial_values in prial_results_sd.items():
    plt.plot(sd_values, prial_values, label=estimator_name, linewidth=2)
plt.title(r'$\mathrm{PRIAL^{INV}}$ of Covariance Estimators Across sd Values', fontsize=14)
plt.xlabel('sd', fontsize=12)
plt.ylabel(r'$\mathrm{PRIAL^{INV}}$', fontsize=12)
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements
def make_data_with_variance(n_samples=100, n_features=500, sd=1, gamma=0.1, random_state=None):
    random_state = np.random.RandomState(random_state)
    base_X_train = random_state.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)  # Scaling factors based on sd parameter
    diag_scaling = np.linspace(1, 10, n_features)    # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        X_train[:, i] *= diag_scaling[i]  # Scale each feature differently

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 100  # Number of samples
n_features = 300  # Number of features
gamma_values = np.arange(0, 1.1, 0.1)  # Range of gamma values

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=500):
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Fit covariance estimators for different gamma values and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'DualShrinkage': []}
for gamma in gamma_values:
    X_train = make_data_with_variance(n_samples, n_features, gamma=gamma, random_state=42)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('DualShrinkage', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across gamma values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(gamma_values, prial_values, label=estimator_name)

plt.title('PRIAL of Covariance Estimators Across Gamma Values')
plt.xlabel('Gamma (Correlation Sparsity)')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements and sparsity
def make_data_with_variance(n_samples=100, n_features=500, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 100  # Number of samples
n_features = 500  # Number of features
sd_values = np.arange(1, 21, 2)  # Range of sd values
random_state = 42
sparsity = 0.1  # Sparsity level

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Fit covariance estimators for different sd values and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train, random_state=random_state)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across sd values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(sd_values, prial_values, label=estimator_name, linestyle='dotted')

plt.title('PRIAL of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()



import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements and sparsity
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.mean([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    rmse = np.sqrt(frob_diff_estimated / (n_features * n_features))
    return rmse

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.6, delta_off_diag=0.3))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name, linestyle='dotted')

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements and sparsity
def make_data_with_variance(n_samples=100, n_features=500, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DualShrinkageEstimator class
class Dual(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DOASD estimator class
class DOASD:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_samples = 100  # Number of samples
n_features = 500  # Number of features
shrinkage_values = np.linspace(0, 1, 11)  # Range of shrinkage values
random_state = 42
sparsity = 0.1  # Sparsity level

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    rmse_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        rmse = np.sqrt(np.mean((estimated_cov - true_cov) ** 2))
        rmse_list.append(rmse)

    return np.mean(rmse_list)

# Generate data
X_train = make_data_with_variance(n_samples, n_features, sd=1, sparsity=sparsity, random_state=random_state)

# Compute RMSE for different shrinkage values
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'LWDual': [], 'DOASD': []}
for shrinkage in shrinkage_values:
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),  # Ledoit-Wolf does not accept a shrinkage parameter
        ('OAS', OAS()),  # OAS does not accept a shrinkage parameter
        ('OASD', ShrunkCovariance(shrinkage=shrinkage)),
        ('LWDual', Dual(diagonal_shrinkage=shrinkage, off_diagonal_shrinkage=shrinkage)),
        ('DOASD', DOASD(delta_diag=shrinkage, delta_off_diag=shrinkage))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across shrinkage values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(shrinkage_values, rmse_values, label=estimator_name, linestyle='dotted')

plt.title('RMSE of Covariance Estimators Across Shrinkage Values')
plt.xlabel('Shrinkage Value')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

# Find the shrinkage value where all estimators have the same RMSE
tolerance = 0.01  # Define a small tolerance for equality
intersection_shrinkage = None

for i, shrinkage in enumerate(shrinkage_values):
    rmses = [rmse_results[estimator][i] for estimator in rmse_results]
    if max(rmses) - min(rmses) < tolerance:
        intersection_shrinkage = shrinkage
        break

print("Shrinkage value where all estimators perform the same RMSE:", intersection_shrinkage)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with weak correlations
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, correlation=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce weak correlations
    correlation_matrix = np.full((n_features, n_features), correlation)
    np.fill_diagonal(correlation_matrix, 1)

    L = np.linalg.cholesky(correlation_matrix)
    X_train = X_train @ L.T

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.mean([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    rmse = np.sqrt(frob_diff_estimated / (n_features * n_features))
    return rmse

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
correlation = 0.1  # Weak correlation
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, correlation=correlation, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name, linestyle='dotted')

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements and sparsity
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=5000, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        sample_indices = np.random.choice(n_samples, n_samples, replace=True)
        bootstrap_sample = X_train[sample_indices, :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    emp_cov_list = [np.cov(X_train[np.random.choice(n_samples, n_samples, replace=True), :], rowvar=False) for _ in range(B)]

    prial = 100 * (1 - (np.mean([np.linalg.norm(est_cov - true_cov, 'fro')**2 for est_cov in estimated_cov_list]) /
                        np.mean([np.linalg.norm(emp_cov - true_cov, 'fro')**2 for emp_cov in emp_cov_list])))

    return prial

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train, random_state=random_state)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(sample_sizes, prial_values, label=estimator_name, linestyle='dotted')

plt.title('PRIAL of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements and sparsity
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Function to compute the Frobenius norm
def frobenius_norm(A):
    return np.linalg.norm(A, 'fro')

# Function to compute the gradient of the loss with respect to rho_diag and rho_off
def compute_gradients(S, Sigma, rho_diag, rho_off):
    n, p = S.shape
    diag_S = np.diag(np.diag(S))
    Sigma_est = (1 - rho_diag) * S + rho_diag * diag_S + (1 - rho_off) * (S - diag_S)

    diff = Sigma_est - Sigma
    grad_rho_diag = 2 * np.sum(diff * (diag_S - S))
    grad_rho_off = 2 * np.sum(diff * (S - diag_S))

    return grad_rho_diag, grad_rho_off

# SGD function to optimize rho_diag and rho_off
def sgd_doad(S, Sigma, learning_rate=0.01, n_iterations=1000, batch_size=10):
    rho_diag = 0.5
    rho_off = 0.5

    n, p = S.shape  # n is number of samples, p is number of features
    indices = np.arange(n)

    for iteration in range(n_iterations):
        np.random.shuffle(indices)
        for start in range(0, n, batch_size):
            end = min(start + batch_size, n)
            batch_indices = indices[start:end]
            S_batch = S[batch_indices, :]
            # Select the correct portion of Sigma using the sample indices
            Sigma_batch = Sigma[np.ix_(batch_indices, batch_indices)] # Use np.ix_ to select a submatrix

            grad_rho_diag, grad_rho_off = compute_gradients(S_batch, Sigma_batch, rho_diag, rho_off)

            rho_diag -= learning_rate * grad_rho_diag
            rho_off -= learning_rate * grad_rho_off

            # Project rho_diag and rho_off to the interval [0, 1]
            rho_diag = np.clip(rho_diag, 0, 1)
            rho_off = np.clip(rho_off, 0, 1)

        # Optional: print progress
        if iteration % 100 == 0:
            print(f"Iteration {iteration}: rho_diag = {rho_diag}, rho_off = {rho_off}")

    return rho_diag, rho_off

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.mean([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    rmse = np.sqrt(frob_diff_estimated / (n_features * n_features))
    return rmse

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name, linestyle='dotted')

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

# Example usage of SGD DOASD
n_samples = 100
n_features = 50
S = np.random.randn(n_samples, n_features)
Sigma = np.cov(S, rowvar=False)

rho_diag, rho_off = sgd_doad(S, Sigma)
print(f"Optimized rho_diag: {rho_diag}, rho_off: {rho_off}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements and sparsity
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Function to compute the Frobenius norm
def frobenius_norm(A):
    return np.linalg.norm(A, 'fro')

# Function to compute the gradient of the loss with respect to rho_diag and rho_off
def compute_gradients(S, Sigma, rho_diag, rho_off):
    n, p = S.shape
    diag_S = np.diag(np.diag(S))
    Sigma_est = (1 - rho_diag) * S + rho_diag * diag_S + (1 - rho_off) * (S - diag_S)

    diff = Sigma_est - Sigma
    grad_rho_diag = 2 * np.sum(diff * (diag_S - S))
    grad_rho_off = 2 * np.sum(diff * (S - diag_S)) # Complete the line for grad_rho_off

    return grad_rho_diag, grad_rho_off

# SGD function to optimize rho_diag and rho_off
def sgd_doad(S, Sigma, learning_rate=0.01, n_iterations=1000, batch_size=10):
    rho_diag = 0.5
    rho_off = 0.5

    n, p = S.shape
    indices = np.arange(n)

    for iteration in range(n_iterations):
        np.random.shuffle(indices)
        for start in range(0, n, batch_size):
            end = min(start + batch_size, n)
            batch_indices = indices[start:end]
            S_batch = S[batch_indices, :]

            grad_rho_diag, grad_rho_off = compute_gradients(S_batch, Sigma, rho_diag, rho_off)

            rho_diag -= learning_rate * grad_rho_diag
            rho_off -= learning_rate * grad_rho_off

            # Project rho_diag and rho_off to the interval [0, 1]
            rho_diag = np.clip(rho_diag, 0, 1)
            rho_off = np.clip(rho_off, 0, 1)

        # Optional: print progress
        if iteration % 100 == 0:
            print(f"Iteration {iteration}: rho_diag = {rho_diag}, rho_off = {rho_off}")

    return rho_diag, rho_off

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.mean([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    rmse = np.sqrt(frob_diff_estimated / (n_features * n_features))
    return rmse

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.6, delta_off_diag=0.3))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name, linestyle='dotted')

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

# Example usage of SGD DOASD
n_samples = 100
n_features = 50
S = np.random.randn(n_samples, n_features)
Sigma = np.cov(S, rowvar=False)

rho_diag, rho_off = sgd_doad(S, Sigma)
print(f"Optimized rho_diag: {rho_diag}, rho_off: {rho_off}")



import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements and sparsity
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Function to compute the Frobenius norm
def frobenius_norm(A):
    return np.linalg.norm(A, 'fro')

# Function to compute the gradient of the loss with respect to rho_diag and rho_off
def compute_gradients(S, Sigma, rho_diag, rho_off):
    n, p = S.shape
    diag_S = np.diag(np.diag(S))
    Sigma_est = (1 - rho_diag) * S + rho_diag * diag_S + (1 - rho_off) * (S - diag_S)

    diff = Sigma_est - Sigma
    grad_rho_diag = 2 * np.sum(diff * (diag_S - S))
    grad_rho_off = 2 * np.sum(diff * (S - diag_S))

    return grad_rho_diag, grad_rho_off

# SGD function to optimize rho_diag and rho_off
def sgd_doad(S, Sigma, learning_rate=0.01, n_iterations=1000, batch_size=10):
    rho_diag = 0.5
    rho_off = 0.5

    n, p = S.shape  # n is number of samples, p is number of features
    indices = np.arange(n)

    for iteration in range(n_iterations):
        np.random.shuffle(indices)
        for start in range(0, n, batch_size):
            end = min(start + batch_size, n)
            batch_indices = indices[start:end]
            S_batch = S[batch_indices, :]
            # Select the correct portion of Sigma using the sample indices
            Sigma_batch = Sigma[np.ix_(batch_indices, batch_indices)] # Use np.ix_ to select a submatrix

            grad_rho_diag, grad_rho_off = compute_gradients(S_batch, Sigma_batch, rho_diag, rho_off)

            rho_diag -= learning_rate * grad_rho_diag
            rho_off -= learning_rate * grad_rho_off

            # Project rho_diag and rho_off to the interval [0, 1]
            rho_diag = np.clip(rho_diag, 0, 1)
            rho_off = np.clip(rho_off, 0, 1)

        # Optional: print progress
        if iteration % 100 == 0:
            print(f"Iteration {iteration}: rho_diag = {rho_diag}, rho_off = {rho_off}")

    return rho_diag, rho_off

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.mean([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    rmse = np.sqrt(frob_diff_estimated / (n_features * n_features))
    return rmse

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    color = 'black' if estimator_name == 'Ledoit-Wolf' else None  # Set color to black for Ledoit-Wolf
    plt.plot(sample_sizes, rmse_values, label=estimator_name, linestyle='dotted', color=color)

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

# Example usage of SGD DOASD
n_samples = 100
n_features = 50
S = np.random.randn(n_samples, n_features)
Sigma = np.cov(S, rowvar=False)

rho_diag, rho_off = sgd_doad(S, Sigma)
print(f"Optimized rho_diag: {rho_diag}, rho_off: {rho_off}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a high-dimensional dataset with varying diagonal elements and sparsity
def make_high_dimensional_data(n_samples=100, n_features=300, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Function to compute the Frobenius norm
def frobenius_norm(A):
    return np.linalg.norm(A, 'fro')

# Function to compute the gradient of the loss with respect to rho_diag and rho_off
def compute_gradients(S, Sigma, rho_diag, rho_off):
    n, p = S.shape
    diag_S = np.diag(np.diag(S))
    Sigma_est = (1 - rho_diag) * S + rho_diag * diag_S + (1 - rho_off) * (S - diag_S)

    diff = Sigma_est - Sigma
    grad_rho_diag = 2 * np.sum(diff * (diag_S - S))
    grad_rho_off = 2 * np.sum(diff * (S - diag_S))

    return grad_rho_diag, grad_rho_off

# SGD function to optimize rho_diag and rho_off
def sgd_doad(S, Sigma, learning_rate=0.01, n_iterations=1000, batch_size=10):
    rho_diag = 0.5
    rho_off = 0.5

    n, p = S.shape  # n is number of samples, p is number of features
    indices = np.arange(n)

    for iteration in range(n_iterations):
        np.random.shuffle(indices)
        for start in range(0, n, batch_size):
            end = min(start + batch_size, n)
            batch_indices = indices[start:end]
            S_batch = S[batch_indices, :]
            # Select the correct portion of Sigma using the sample indices
            Sigma_batch = Sigma[np.ix_(batch_indices, batch_indices)] # Use np.ix_ to select a submatrix

            grad_rho_diag, grad_rho_off = compute_gradients(S_batch, Sigma_batch, rho_diag, rho_off)

            rho_diag -= learning_rate * grad_rho_diag
            rho_off -= learning_rate * grad_rho_off

            # Project rho_diag and rho_off to the interval [0, 1]
            rho_diag = np.clip(rho_diag, 0, 1)
            rho_off = np.clip(rho_off, 0, 1)

        # Optional: print progress
        if iteration % 100 == 0:
            print(f"Iteration {iteration}: rho_diag = {rho_diag}, rho_off = {rho_off}")

    return rho_diag, rho_off

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute RMSE for a given estimator
def compute_rmse(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.mean([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    rmse = np.sqrt(frob_diff_estimated / (n_features * n_features))
    return rmse

# Parameters
n_features = 500  # High-dimensional data
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Fit covariance estimators for different sample sizes and compute RMSE
rmse_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_high_dimensional_data(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        rmse = compute_rmse(estimator, X_train, random_state=random_state)
        rmse_results[estimator_name].append(rmse)

# Plot RMSE across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, rmse_values in rmse_results.items():
    plt.plot(sample_sizes, rmse_values, label=estimator_name, linestyle='dotted')

plt.title('RMSE of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.legend()
plt.grid(True)
plt.show()

# Example usage of SGD DOASD
n_samples = 100
n_features = 50
S = np.random.randn(n_samples, n_features)
Sigma = np.cov(S, rowvar=False)

rho_diag, rho_off = sgd_doad(S, Sigma)
print(f"Optimized rho_diag: {rho_diag}, rho_off: {rho_off}")

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements and sparsity
def make_data_with_variance(n_samples=100, n_features=500, sd=1, sparsity=0.1, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_features = 500  # Number of features
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Function to compute PRIAL for a given estimator
def compute_prial(estimator, X_train, B=500, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    sample_cov_list = []
    estimated_cov_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        sample_cov_list.append(sample_cov)
        estimated_cov_list.append(estimated_cov)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(sample_cov_list[b] - true_cov, 'fro')**2 for b in range(B)])

    prial = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prial

# Fit covariance estimators for different sample sizes and compute PRIAL
prial_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.0)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prial = compute_prial(estimator, X_train, random_state=random_state)
        prial_results[estimator_name].append(prial)

# Plot PRIAL across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prial_values in prial_results.items():
    plt.plot(sample_sizes, prial_values, label=estimator_name, linestyle='dotted')

plt.title('PRIAL of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('PRIAL')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements and sparsity
def make_data_with_variance(n_samples=100, n_features=500, sd=10, sparsity=0.5, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Parameters
n_features = 500  # Number of features
sample_sizes = np.arange(50, 501, 50)  # Range of sample sizes
random_state = 42
sparsity = 0.1  # Sparsity level
sd = 10  # Fixed sd value

# Function to compute PRIALINV for a given estimator
def compute_prialinv(estimator, X_train, B=500, random_state=None, regularization=1e-6):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    true_cov_inv = np.linalg.inv(true_cov + regularization * np.eye(n_features))
    sample_cov_list = []
    estimated_cov_inv_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        estimator.fit(bootstrap_sample)
        estimated_cov = estimator.covariance_

        try:
            estimated_cov_inv = np.linalg.inv(estimated_cov + regularization * np.eye(n_features))
        except np.linalg.LinAlgError:
            estimated_cov_inv = np.linalg.inv(estimated_cov + regularization * np.eye(n_features))

        sample_cov_list.append(sample_cov)
        estimated_cov_inv_list.append(estimated_cov_inv)

    frob_diff_estimated = np.sum([np.linalg.norm(estimated_cov_inv_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])
    frob_diff_sample = np.sum([np.linalg.norm(np.linalg.inv(sample_cov_list[b] + regularization * np.eye(n_features)) - true_cov_inv, 'fro')**2 for b in range(B)])

    prialinv = (1 - frob_diff_estimated / frob_diff_sample) * 100
    return prialinv

# Fit covariance estimators for different sample sizes and compute PRIALINV
prialinv_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for n_samples in sample_sizes:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prialinv = compute_prialinv(estimator, X_train, random_state=random_state)
        prialinv_results[estimator_name].append(prialinv)

# Plot PRIALINV across sample sizes for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prialinv_values in prialinv_results.items():
    plt.plot(sample_sizes, prialinv_values, label=estimator_name, linestyle='dotted')

plt.title('PRIALINV of Covariance Estimators Across Sample Sizes')
plt.xlabel('Sample Size')
plt.ylabel('PRIALINV')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.covariance import LedoitWolf, OAS, ShrunkCovariance

# Function to create a dataset with varying diagonal elements and sparsity
def make_data_with_variance(n_samples=100, n_features=500, sd=1, sparsity=0.5, random_state=None):
    np.random.seed(random_state)
    base_X_train = np.random.normal(size=(n_samples, n_features))
    scaling_factors = np.linspace(1, sd, n_features)
    diag_scaling = np.linspace(1, 10, n_features)  # Varying scaling factors for diagonal elements

    X_train = base_X_train * scaling_factors

    # Introduce sparsity in the covariance matrix
    for i in range(n_features):
        if np.random.rand() > sparsity:
            X_train[:, i] *= diag_scaling[i]  # Scale each feature differently
        else:
            X_train[:, i] = 0  # Set some features to zero to introduce sparsity

    return X_train

# Define the DOASD estimator class with different levels of shrinkage
class DOASD(ShrunkCovariance):
    def __init__(self, diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3):
        super().__init__()
        self.diagonal_shrinkage = diagonal_shrinkage
        self.off_diagonal_shrinkage = off_diagonal_shrinkage

    def _compute_covariance(self, X):
        emp_cov = np.cov(X, rowvar=False)
        return emp_cov

    def fit(self, X, y=None):
        emp_cov = self._compute_covariance(X)
        n_features = emp_cov.shape[0]

        # Apply shrinkage
        shrunk_diag_cov = emp_cov * (1 - self.diagonal_shrinkage) + np.diag(np.diag(emp_cov)) * self.diagonal_shrinkage
        shrunk_cov = shrunk_diag_cov * (1 - self.off_diagonal_shrinkage) + np.diag(np.diag(shrunk_diag_cov)) * self.off_diagonal_shrinkage

        self.covariance_ = shrunk_cov
        return self

# Define the DualShrinkageEstimator class
class DualShrinkageEstimator:
    def __init__(self, delta_diag=0.4, delta_off_diag=0.3):
        self.delta_diag = delta_diag
        self.delta_off_diag = delta_off_diag

    def fit(self, X):
        sample_cov = np.cov(X, rowvar=False)
        D = np.diag(np.diag(sample_cov))
        O = sample_cov - D

        diag_target = np.diag(np.var(X, axis=0))
        off_diag_target = np.zeros_like(O)

        shrunk_diag = self.delta_diag * D + (1 - self.delta_diag) * diag_target
        shrunk_off_diag = self.delta_off_diag * O + (1 - self.delta_off_diag) * off_diag_target

        self.covariance_ = shrunk_diag + shrunk_off_diag
        return self

# Function to compute PRIALINV for a given estimator with regularization
def compute_prialinv(estimator, X_train, B=500, reg=1e-6, random_state=None):
    np.random.seed(random_state)
    n_samples, n_features = X_train.shape
    true_cov = np.cov(X_train, rowvar=False)
    true_cov_inv = np.linalg.inv(true_cov + reg * np.eye(n_features))  # Regularize the true covariance matrix
    sample_cov_inv_list = []
    estimated_cov_inv_list = []

    for _ in range(B):
        bootstrap_sample = X_train[np.random.choice(n_samples, n_samples, replace=True), :]
        sample_cov = np.cov(bootstrap_sample, rowvar=False)
        sample_cov_inv = np.linalg.inv(sample_cov + reg * np.eye(n_features))  # Regularize the sample covariance matrix
        estimator.fit(bootstrap_sample)
        estimated_cov_inv = np.linalg.inv(estimator.covariance_ + reg * np.eye(n_features))  # Regularize the estimated covariance matrix

        sample_cov_inv_list.append(sample_cov_inv)
        estimated_cov_inv_list.append(estimated_cov_inv)

    frob_diff_sample_inv = np.sum([np.linalg.norm(sample_cov_inv_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])
    frob_diff_estimated_inv = np.sum([np.linalg.norm(estimated_cov_inv_list[b] - true_cov_inv, 'fro')**2 for b in range(B)])

    prialinv = (1 - (frob_diff_estimated_inv / frob_diff_sample_inv)) * 100
    return prialinv

# Parameters
n_samples = 100  # Number of samples
n_features = 500  # Number of features
sd_values = np.arange(1, 21, 2)  # Range of sd values
random_state = 42
sparsity = 0.1  # Sparsity level

# Fit covariance estimators for different sd values and compute PRIALINV
prialinv_results = {'Ledoit-Wolf': [], 'OAS': [], 'OASD': [], 'DOASD': [], 'LWDual': []}
for sd in sd_values:
    X_train = make_data_with_variance(n_samples, n_features, sd=sd, sparsity=sparsity, random_state=random_state)
    for estimator_name, estimator in [
        ('Ledoit-Wolf', LedoitWolf()),
        ('OAS', OAS()),
        ('OASD', ShrunkCovariance(shrinkage=0.4)),
        ('DOASD', DOASD(diagonal_shrinkage=0.4, off_diagonal_shrinkage=0.3)),
        ('LWDual', DualShrinkageEstimator(delta_diag=0.4, delta_off_diag=0.3))
    ]:
        prialinv = compute_prialinv(estimator, X_train, random_state=random_state)
        prialinv_results[estimator_name].append(prialinv)

# Plot PRIALINV across sd values for each estimator
plt.figure(figsize=(12, 6))
for estimator_name, prialinv_values in prialinv_results.items():
    plt.plot(sd_values, prialinv_values, label=estimator_name, linestyle='dotted')

plt.title('PRIALINV of Covariance Estimators Across sd Values')
plt.xlabel('sd')
plt.ylabel('PRIALINV')
plt.legend()
plt.grid(True)
plt.show()